import sys
import threading
import queue
import time
import traceback

import torch

try:
    import whisper
    import sounddevice as sd
    import numpy as np
except ImportError as e:
    print(f"ì˜¤ë¥˜: STT ì„œë¹„ìŠ¤ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ ({e}).")
    print("ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì—¬ ì„¤ì¹˜í•˜ì„¸ìš”:")
    print("uv add openai-whisper sounddevice numpy")
    raise

SAMPLE_RATE = 16000
RECORD_SECONDS = 5
SILENCE_THRESHOLD = 500
SILENCE_DURATION = 1.5


class STTService:
    """
    Whisperë¥¼ ì´ìš©í•œ ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜ ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
    """

    def __init__(self, model_name="base", device_preference="auto"):
        """
        ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ë° Whisper ëª¨ë¸ ë¡œë“œ
        Args:
            model_name (str): ì‚¬ìš©í•  Whisper ëª¨ë¸ ì´ë¦„ ë˜ëŠ” ê²½ë¡œ
            device_preference (str): ì‚¬ìš©í•  ì¥ì¹˜ ì„¤ì • ('auto', 'cpu', 'mps')
        """
        self.model_name = model_name
        self.device_preference = device_preference
        self.whisper_model = None
        self.audio_queue = queue.Queue()
        self.stop_recording_event = threading.Event()
        self._load_model()

    def _load_model(self):
        """Whisper ëª¨ë¸ ë¡œë“œ (ì‚¬ìš©ì ì„¤ì • ë˜ëŠ” ìë™ ê°ì§€ ê¸°ë°˜)"""
        print(
            f"Whisper ëª¨ë¸ '{self.model_name}' ë¡œë“œ ì¤‘ (ì„ í˜¸ ì¥ì¹˜: {self.device_preference})..."
        )
        device = "cpu"

        if self.device_preference == "cpu":
            print("ì‚¬ìš©ì ì„¤ì •ì— ë”°ë¼ CPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            device = "cpu"
        elif self.device_preference == "mps":
            if hasattr(torch.backends, "mps") and torch.backends.mps.is_available():
                print("ì‚¬ìš©ì ì„¤ì • 'mps' í™•ì¸ë¨. MPS (Apple Silicon GPU)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                device = "mps"
            else:
                print(
                    "ê²½ê³ : ì‚¬ìš©ì ì„¤ì • 'mps'ì´ì§€ë§Œ MPSë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPUë¡œ fallbackí•©ë‹ˆë‹¤."
                )
                device = "cpu"
        elif self.device_preference == "auto":
            # ìë™ ê°ì§€ ë¡œì§ (MPS ìš°ì„ )
            if hasattr(torch.backends, "mps") and torch.backends.mps.is_available():
                print(
                    "ìë™ ê°ì§€: MPS (Apple Silicon GPU) ì‚¬ìš© ê°€ëŠ¥. ì¥ì¹˜ë¥¼ 'mps'ë¡œ ì„¤ì •í•©ë‹ˆë‹¤."
                )
                device = "mps"
            #     device = "cuda"
            else:
                print("ìë™ ê°ì§€: MPS/CUDA ì‚¬ìš© ë¶ˆê°€. CPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                device = "cpu"

        try:
            self.whisper_model = whisper.load_model(
                self.model_name, device=device, download_root="./models"
            )
            print(f"Whisper ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ì‚¬ìš© ì¥ì¹˜: {device}).")
        except Exception as e:
            print(f"Whisper ëª¨ë¸ ë¡œë“œ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
            traceback.print_exc()
            raise RuntimeError(f"Whisper ëª¨ë¸ '{self.model_name}' ë¡œë“œ ì‹¤íŒ¨") from e

    def _audio_callback(self, indata, frames, time, status):
        """ì‚¬ìš´ë“œ ì¥ì¹˜ì—ì„œ í˜¸ì¶œë˜ëŠ” ì½œë°± í•¨ìˆ˜"""
        if status:
            print(f"ì˜¤ë””ì˜¤ ì½œë°± ìƒíƒœ: {status}", file=sys.stderr)
        self.audio_queue.put(indata.copy())

    def record_audio(self):
        """
        ë§ˆì´í¬ì—ì„œ ì˜¤ë””ì˜¤ë¥¼ ë…¹ìŒí•˜ê³  NumPy ë°°ì—´ë¡œ ë°˜í™˜.
        ì¹¨ë¬µ ë˜ëŠ” ìµœëŒ€ ë…¹ìŒ ì‹œê°„ì— ë„ë‹¬í•˜ë©´ ìë™ìœ¼ë¡œ ì¤‘ì§€ë©ë‹ˆë‹¤.
        ì´ í•¨ìˆ˜ëŠ” ë™ê¸°ì ìœ¼ë¡œ ì‹¤í–‰ë˜ë¯€ë¡œ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ í˜¸ì¶œí•´ì•¼ í•©ë‹ˆë‹¤.
        """
        self.audio_queue = queue.Queue()
        self.stop_recording_event.clear()

        print(
            f"\nğŸ¤ {RECORD_SECONDS}ì´ˆ ë™ì•ˆ ë˜ëŠ” {SILENCE_DURATION}ì´ˆ ì¹¨ë¬µ ì‹œ ë…¹ìŒ ì‹œì‘..."
        )
        print(
            "(ë…¹ìŒì„ ì¤‘ë‹¨í•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš” - í„°ë¯¸ë„ì— ë”°ë¼ ë™ì‘ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)"
        )

        stream = None
        try:
            stream = sd.InputStream(
                samplerate=SAMPLE_RATE,
                channels=1,
                dtype="int16",
                callback=self._audio_callback,
                blocksize=int(SAMPLE_RATE * 0.1),
            )
            stream.start()

            recorded_frames = []
            silent_frames = 0
            total_frames = 0
            frames_per_second = SAMPLE_RATE
            silence_limit = int(SILENCE_DURATION * frames_per_second)
            max_frames = int(RECORD_SECONDS * frames_per_second)
            last_sound_time = time.time()

            while not self.stop_recording_event.is_set():
                try:
                    frame = self.audio_queue.get(timeout=0.1)
                    recorded_frames.append(frame)
                    current_frames = len(frame)
                    total_frames += current_frames

                    rms = np.sqrt(np.mean(frame.astype(np.float32) ** 2))
                    if rms < SILENCE_THRESHOLD:
                        if time.time() - last_sound_time > SILENCE_DURATION:
                            print("ë…¹ìŒ ì¤‘ì§€ (ì¹¨ë¬µ ê°ì§€).")
                            break
                    else:
                        last_sound_time = time.time()
                        silent_frames = 0

                    if total_frames >= max_frames:
                        print("ë…¹ìŒ ì¤‘ì§€ (ìµœëŒ€ ì‹œê°„ ë„ë‹¬).")
                        break

                except queue.Empty:
                    if time.time() - last_sound_time > SILENCE_DURATION:
                        print("ë…¹ìŒ ì¤‘ì§€ (íƒ€ì„ì•„ì›ƒ í›„ ì¹¨ë¬µ ê°ì§€).")
                        break
                    if total_frames >= max_frames:
                        print("ë…¹ìŒ ì¤‘ì§€ (ì‹œê°„ ì´ˆê³¼).")
                        break
                    if self.stop_recording_event.is_set():
                        print("ë…¹ìŒ ì¤‘ì§€ (ì™¸ë¶€ ìš”ì²­).")
                        break
                    continue
                except Exception as e:
                    print(f"ë…¹ìŒ ë£¨í”„ ì¤‘ ì˜¤ë¥˜: {e}")
                    traceback.print_exc()
                    self.stop_recording_event.set()
                    break

        except sd.PortAudioError as pae:
            print(f"ì˜¤ë””ì˜¤ ì¥ì¹˜ ì˜¤ë¥˜: {pae}")
            print("ì‚¬ìš© ê°€ëŠ¥í•œ ì˜¤ë””ì˜¤ ì…ë ¥ ì¥ì¹˜ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
            return None
        except Exception as e:
            print(f"ë…¹ìŒ ìŠ¤íŠ¸ë¦¼ ì‹œì‘ ì¤‘ ì˜¤ë¥˜: {e}")
            traceback.print_exc()
            return None
        finally:
            if stream is not None:
                try:
                    if stream.active:
                        stream.stop()
                    stream.close()
                except Exception as e:
                    print(f"ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            print("ë…¹ìŒ ì™„ë£Œ.")

        if not recorded_frames:
            print("ë…¹ìŒëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

        try:
            audio_data = np.concatenate(recorded_frames, axis=0)
            audio_float32 = audio_data.flatten().astype(np.float32) / 32768.0
            return audio_float32
        except Exception as e:
            print(f"ë…¹ìŒ ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            traceback.print_exc()
            return None

    def transcribe_audio(self, audio_data):
        """
        Whisper ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜.
        ì´ í•¨ìˆ˜ëŠ” ë™ê¸°ì ìœ¼ë¡œ ì‹¤í–‰ë˜ë¯€ë¡œ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ í˜¸ì¶œí•´ì•¼ í•©ë‹ˆë‹¤.
        """
        if self.whisper_model is None:
            print("ì˜¤ë¥˜: Whisper ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return ""
        if audio_data is None or len(audio_data) == 0:
            print("ë³€í™˜í•  ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return ""

        print(f"Whisperë¡œ ìŒì„± ë³€í™˜ ì¤‘ (ì¥ì¹˜: {self.whisper_model.device})...")
        try:
            use_fp16 = self.whisper_model.device != "cpu"

            result = self.whisper_model.transcribe(audio_data, fp16=use_fp16)
            transcribed_text = result["text"].strip()
            print("ìŒì„± ë³€í™˜ ì™„ë£Œ.")
            return transcribed_text
        except Exception as e:
            print(f"Whisper ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            traceback.print_exc()
            return ""

    def stop_recording(self):
        """ì™¸ë¶€ì—ì„œ ë…¹ìŒì„ ì¤‘ì§€ì‹œí‚¬ ë•Œ í˜¸ì¶œ"""
        print("ë…¹ìŒ ì¤‘ì§€ ìš”ì²­ ìˆ˜ì‹ .")
        self.stop_recording_event.set()


async def test_stt_service():
    """stt_service.py ë‹¨ë… ì‹¤í–‰ ì‹œ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("STT ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    try:
        stt = STTService(model_name="base")

        print("\n--- ë…¹ìŒ í…ŒìŠ¤íŠ¸ ---")
        audio = await asyncio.to_thread(stt.record_audio)

        if audio is not None:
            print(f"ë…¹ìŒëœ ì˜¤ë””ì˜¤ ë°ì´í„° ê¸¸ì´: {len(audio)} ìƒ˜í”Œ")
            print("\n--- ë³€í™˜ í…ŒìŠ¤íŠ¸ ---")
            text = await asyncio.to_thread(stt.transcribe_audio, audio)
            print(f"\në³€í™˜ëœ í…ìŠ¤íŠ¸: '{text}'")
        else:
            print("ë…¹ìŒì— ì‹¤íŒ¨í•˜ì—¬ ë³€í™˜ í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")

    except RuntimeError as e:
        print(f"STT ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    except Exception as e:
        print(f"í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        traceback.print_exc()

    print("\nSTT ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ ì¢…ë£Œ.")


if __name__ == "__main__":
    try:
        asyncio.run(test_stt_service())
    except KeyboardInterrupt:
        print("\ní…ŒìŠ¤íŠ¸ ì¤‘ë‹¨ë¨.")
    except Exception as e:
        print(f"\ní…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ìµœìƒìœ„ ì˜¤ë¥˜: {e}")
        traceback.print_exc()
