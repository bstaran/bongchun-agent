import sys
import os
import threading
import queue
import time
import traceback
import io
import wave

import torch

try:
    from faster_whisper import WhisperModel
    import sounddevice as sd
    import numpy as np
except ImportError as e:
    print(f"ì˜¤ë¥˜: Whisper STT ì„œë¹„ìŠ¤ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ ({e}).")
    print("ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì—¬ ì„¤ì¹˜í•˜ì„¸ìš”:")
    print("uv add faster-whisper sounddevice numpy torch")

try:
    from google.cloud import speech
except ImportError:
    print("ê²½ê³ : Google Cloud Speech ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("Google STTë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì—¬ ì„¤ì¹˜í•˜ì„¸ìš”:")
    print("uv add google-cloud-speech")
    speech = None

SAMPLE_RATE = 16000
RECORD_SECONDS = 10
SILENCE_THRESHOLD = 500
SILENCE_DURATION = 1.5


class STTService:
    """
    Whisper ë˜ëŠ” Google Cloudë¥¼ ì´ìš©í•œ ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜ ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
    """

    def __init__(
        self,
        provider="whisper",
        whisper_model_name="base",
        whisper_device_preference="auto",
        google_lang_code="ko-KR",
    ):
        """
        ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ë° ì„ íƒëœ STT ì œê³µì ì„¤ì •
        Args:
            provider (str): ì‚¬ìš©í•  STT ì œê³µì ('whisper' ë˜ëŠ” 'google')
            whisper_model_name (str): Whisper ì‚¬ìš© ì‹œ ëª¨ë¸ ì´ë¦„ ë˜ëŠ” ê²½ë¡œ
            whisper_device_preference (str): Whisper ì‚¬ìš© ì‹œ ì¥ì¹˜ ì„¤ì • ('auto', 'cpu', 'mps')
            google_lang_code (str): Google Cloud STT ì‚¬ìš© ì‹œ ì–¸ì–´ ì½”ë“œ
        """
        self.provider = provider
        self.audio_queue = queue.Queue()
        self.stop_recording_event = threading.Event()

        self.whisper_model = None
        self.whisper_device = None
        self.google_client = None
        self.google_lang_code = google_lang_code

        if self.provider == "whisper":
            self.whisper_model_name = whisper_model_name
            self.whisper_device_preference = whisper_device_preference
            self._load_whisper_model()
        elif self.provider == "google":
            if speech is None:
                raise RuntimeError(
                    "Google Cloud Speech ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                )
            try:
                print("Google Cloud Speech í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘...")
                self.google_client = speech.SpeechClient()
                print("Google Cloud Speech í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ.")
            except Exception as e:
                print(f"Google Cloud Speech í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                traceback.print_exc()
                raise RuntimeError("Google Cloud Speech í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨") from e
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” STT ì œê³µì: {provider}")

    def _load_whisper_model(self):
        """Whisper ëª¨ë¸ ë¡œë“œ (ì‚¬ìš©ì ì„¤ì • ë˜ëŠ” ìë™ ê°ì§€ ê¸°ë°˜)"""
        if "WhisperModel" not in globals():
            raise RuntimeError("Faster Whisper ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        print(
            f"Whisper ëª¨ë¸ '{self.whisper_model_name}' ë¡œë“œ ì¤‘ (ì„ í˜¸ ì¥ì¹˜: {self.whisper_device_preference})..."
        )
        device = "cpu"

        if self.device_preference == "cpu":
            print("ì‚¬ìš©ì ì„¤ì •ì— ë”°ë¼ CPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            device = "cpu"
        elif self.device_preference == "mps":
            if hasattr(torch.backends, "mps") and torch.backends.mps.is_available():
                print("ì‚¬ìš©ì ì„¤ì • 'mps' í™•ì¸ë¨. MPS (Apple Silicon GPU)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                device = "mps"
            else:
                print(
                    "ê²½ê³ : ì‚¬ìš©ì ì„¤ì • 'mps'ì´ì§€ë§Œ MPSë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPUë¡œ fallbackí•©ë‹ˆë‹¤."
                )
                device = "cpu"
        elif self.device_preference == "auto":
            # ìë™ ê°ì§€ ë¡œì§ (MPS ìš°ì„ )
            if hasattr(torch.backends, "mps") and torch.backends.mps.is_available():
                print(
                    "ìë™ ê°ì§€: MPS (Apple Silicon GPU) ì‚¬ìš© ê°€ëŠ¥. ì¥ì¹˜ë¥¼ 'mps'ë¡œ ì„¤ì •í•©ë‹ˆë‹¤."
                )
                device = "mps"
            #     device = "cuda"
            else:
                print("ìë™ ê°ì§€: MPS/CUDA ì‚¬ìš© ë¶ˆê°€. CPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                device = "cpu"

        print(
            f"ì‹¤ì œ WhisperModel ë¡œë“œ ì‹œë„ ëª¨ë¸: '{self.model_name}', ì¥ì¹˜: '{device}'"
        )
        try:
            self.whisper_model = WhisperModel(
                self.whisper_model_name,
                device=device,
                compute_type="int8",
                download_root="../models",
            )
            self.whisper_device = device

            print(f"Whisper ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ì‚¬ìš© ì¥ì¹˜: {self.whisper_device}).")
        except Exception as e:
            print(f"Whisper ëª¨ë¸ ë¡œë“œ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
            traceback.print_exc()
            raise RuntimeError(
                f"Whisper ëª¨ë¸ '{self.whisper_model_name}' ë¡œë“œ ì‹¤íŒ¨"
            ) from e

    def _audio_callback(self, indata, frames, time, status):
        """ì‚¬ìš´ë“œ ì¥ì¹˜ì—ì„œ í˜¸ì¶œë˜ëŠ” ì½œë°± í•¨ìˆ˜"""
        if status:
            print(f"ì˜¤ë””ì˜¤ ì½œë°± ìƒíƒœ: {status}", file=sys.stderr)
        self.audio_queue.put(indata.copy())

    def record_audio(self):
        """
        ë§ˆì´í¬ì—ì„œ ì˜¤ë””ì˜¤ë¥¼ ë…¹ìŒí•˜ê³  NumPy ë°°ì—´ë¡œ ë°˜í™˜.
        ì¹¨ë¬µ ë˜ëŠ” ìµœëŒ€ ë…¹ìŒ ì‹œê°„ì— ë„ë‹¬í•˜ë©´ ìë™ìœ¼ë¡œ ì¤‘ì§€ë©ë‹ˆë‹¤.
        ì´ í•¨ìˆ˜ëŠ” ë™ê¸°ì ìœ¼ë¡œ ì‹¤í–‰ë˜ë¯€ë¡œ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ í˜¸ì¶œí•´ì•¼ í•©ë‹ˆë‹¤.
        """
        self.audio_queue = queue.Queue()
        self.stop_recording_event.clear()

        print(
            f"\nğŸ¤ {RECORD_SECONDS}ì´ˆ ë™ì•ˆ ë˜ëŠ” {SILENCE_DURATION}ì´ˆ ì¹¨ë¬µ ì‹œ ë…¹ìŒ ì‹œì‘..."
        )
        print(
            "(ë…¹ìŒì„ ì¤‘ë‹¨í•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš” - í„°ë¯¸ë„ì— ë”°ë¼ ë™ì‘ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)"
        )

        stream = None
        try:
            stream = sd.InputStream(
                samplerate=SAMPLE_RATE,
                channels=1,
                dtype="int16",
                callback=self._audio_callback,
                blocksize=int(SAMPLE_RATE * 0.1),
            )
            stream.start()

            recorded_frames = []
            silent_frames = 0
            total_frames = 0
            frames_per_second = SAMPLE_RATE
            silence_limit = int(SILENCE_DURATION * frames_per_second)
            max_frames = int(RECORD_SECONDS * frames_per_second)
            last_sound_time = time.time()

            while not self.stop_recording_event.is_set():
                try:
                    frame = self.audio_queue.get(timeout=0.1)
                    recorded_frames.append(frame)
                    current_frames = len(frame)
                    total_frames += current_frames

                    rms = np.sqrt(np.mean(frame.astype(np.float32) ** 2))
                    if rms < SILENCE_THRESHOLD:
                        if time.time() - last_sound_time > SILENCE_DURATION:
                            print("ë…¹ìŒ ì¤‘ì§€ (ì¹¨ë¬µ ê°ì§€).")
                            break
                    else:
                        last_sound_time = time.time()
                        silent_frames = 0

                    if total_frames >= max_frames:
                        print("ë…¹ìŒ ì¤‘ì§€ (ìµœëŒ€ ì‹œê°„ ë„ë‹¬).")
                        break

                except queue.Empty:
                    if time.time() - last_sound_time > SILENCE_DURATION:
                        print("ë…¹ìŒ ì¤‘ì§€ (íƒ€ì„ì•„ì›ƒ í›„ ì¹¨ë¬µ ê°ì§€).")
                        break
                    if total_frames >= max_frames:
                        print("ë…¹ìŒ ì¤‘ì§€ (ì‹œê°„ ì´ˆê³¼).")
                        break
                    if self.stop_recording_event.is_set():
                        print("ë…¹ìŒ ì¤‘ì§€ (ì™¸ë¶€ ìš”ì²­).")
                        break
                    continue
                except Exception as e:
                    print(f"ë…¹ìŒ ë£¨í”„ ì¤‘ ì˜¤ë¥˜: {e}")
                    traceback.print_exc()
                    self.stop_recording_event.set()
                    break

        except sd.PortAudioError as pae:
            print(f"ì˜¤ë””ì˜¤ ì¥ì¹˜ ì˜¤ë¥˜: {pae}")
            print("ì‚¬ìš© ê°€ëŠ¥í•œ ì˜¤ë””ì˜¤ ì…ë ¥ ì¥ì¹˜ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
            return None
        except Exception as e:
            print(f"ë…¹ìŒ ìŠ¤íŠ¸ë¦¼ ì‹œì‘ ì¤‘ ì˜¤ë¥˜: {e}")
            traceback.print_exc()
            return None
        finally:
            if stream is not None:
                try:
                    if stream.active:
                        stream.stop()
                    stream.close()
                except Exception as e:
                    print(f"ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            print("ë…¹ìŒ ì™„ë£Œ.")

        if not recorded_frames:
            print("ë…¹ìŒëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

        try:
            audio_data = np.concatenate(recorded_frames, axis=0)
            audio_float32 = audio_data.flatten().astype(np.float32) / 32768.0
            return audio_float32
        except Exception as e:
            print(f"ë…¹ìŒ ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            traceback.print_exc()
            return None

    def _numpy_to_wav_bytes(self, audio_data_np: np.ndarray) -> bytes:
        """NumPy float32 ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ WAV í˜•ì‹ì˜ ë°”ì´íŠ¸ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ë³€í™˜"""
        if audio_data_np is None or audio_data_np.size == 0:
            return b""
        # float32 [-1.0, 1.0] -> int16 [-32768, 32767]
        audio_data_int16 = (audio_data_np * 32767).astype(np.int16)

        bytes_io = io.BytesIO()
        with wave.open(bytes_io, "wb") as wf:
            wf.setnchannels(1)  # Mono
            wf.setsampwidth(2)  # 16-bit = 2 bytes
            wf.setframerate(SAMPLE_RATE)
            wf.writeframes(audio_data_int16.tobytes())
        return bytes_io.getvalue()

    def transcribe_audio(self, audio_data_np: np.ndarray) -> str:
        """
        ì„ íƒëœ STT ì œê³µìë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜.
        Args:
            audio_data_np (np.ndarray): float32 í˜•ì‹ì˜ NumPy ì˜¤ë””ì˜¤ ë°ì´í„°
        Returns:
            str: ë³€í™˜ëœ í…ìŠ¤íŠ¸
        """
        if audio_data_np is None or audio_data_np.size == 0:
            print("ë³€í™˜í•  ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return ""

        if self.provider == "whisper":
            return self._transcribe_whisper(audio_data_np)
        elif self.provider == "google":
            return self._transcribe_google(audio_data_np)
        else:
            print(f"ì˜¤ë¥˜: ì•Œ ìˆ˜ ì—†ëŠ” STT ì œê³µì '{self.provider}'")
            return ""

    def _transcribe_whisper(self, audio_data_np: np.ndarray) -> str:
        """Whisperë¥¼ ì‚¬ìš©í•˜ì—¬ ë³€í™˜"""
        if self.whisper_model is None:
            print("ì˜¤ë¥˜: Whisper ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return ""
        print(f"Whisperë¡œ ìŒì„± ë³€í™˜ ì¤‘ (ì¥ì¹˜: {self.whisper_device})...")
        try:
            segments, _info = self.whisper_model.transcribe(
                audio_data_np, language="ko"
            )
            transcribed_text = "".join(segment.text for segment in segments).strip()
            print("Whisper ë³€í™˜ ì™„ë£Œ.")
            return transcribed_text
        except Exception as e:
            print(f"Whisper ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            traceback.print_exc()
            return ""

    def _transcribe_google(self, audio_data_np: np.ndarray) -> str:
        """Google Cloud Speechë¥¼ ì‚¬ìš©í•˜ì—¬ ë³€í™˜"""
        if self.google_client is None:
            print("ì˜¤ë¥˜: Google Cloud Speech í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return ""

        print(f"Google Cloud STTë¡œ ìŒì„± ë³€í™˜ ì¤‘ (ì–¸ì–´: {self.google_lang_code})...")
        try:
            audio_bytes = self._numpy_to_wav_bytes(audio_data_np)
            if not audio_bytes:
                print("ì˜¤ë¥˜: ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ WAV ë°”ì´íŠ¸ë¡œ ë³€í™˜ ì‹¤íŒ¨.")
                return ""

            audio = speech.RecognitionAudio(content=audio_bytes)
            config = speech.RecognitionConfig(
                encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
                sample_rate_hertz=SAMPLE_RATE,
                language_code=self.google_lang_code,
            )

            response = self.google_client.recognize(config=config, audio=audio)

            if response.results:
                transcribed_text = (
                    response.results[0].alternatives[0].transcript.strip()
                )
                print("Google Cloud STT ë³€í™˜ ì™„ë£Œ.")
                return transcribed_text
            else:
                print("Google Cloud STT ê²°ê³¼ ì—†ìŒ.")
                return ""
        except Exception as e:
            print(f"Google Cloud STT ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            traceback.print_exc()
            return ""

    def stop_recording(self):
        """ì™¸ë¶€ì—ì„œ ë…¹ìŒì„ ì¤‘ì§€ì‹œí‚¬ ë•Œ í˜¸ì¶œ"""
        print("ë…¹ìŒ ì¤‘ì§€ ìš”ì²­ ìˆ˜ì‹ .")
        self.stop_recording_event.set()


async def test_stt_service():
    """stt_service.py ë‹¨ë… ì‹¤í–‰ ì‹œ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("STT ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    test_provider = os.getenv("STT_PROVIDER", "whisper").lower()
    print(f"í…ŒìŠ¤íŠ¸í•  STT ì œê³µì: {test_provider}")

    if test_provider == "google" and not os.getenv("GOOGLE_APPLICATION_CREDENTIALS"):
        print(
            "\nê²½ê³ : Google STT í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ GOOGLE_APPLICATION_CREDENTIALS í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤."
        )
        print("í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\n")
        return
    elif test_provider == "google" and os.getenv("GOOGLE_APPLICATION_CREDENTIALS"):
        if not os.path.exists(os.getenv("GOOGLE_APPLICATION_CREDENTIALS")):
            print(
                f"\nê²½ê³ : GOOGLE_APPLICATION_CREDENTIALS ê²½ë¡œ '{os.getenv('GOOGLE_APPLICATION_CREDENTIALS')}'ì— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."
            )
            print("Google STT í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\n")
            return

    try:
        stt = STTService(
            provider=test_provider,
            whisper_model_name=os.getenv("WHISPER_MODEL", "base"),
            whisper_device_preference=os.getenv("WHISPER_DEVICE", "auto"),
        )

        print("\n--- ë…¹ìŒ í…ŒìŠ¤íŠ¸ ---")
        audio_np = await asyncio.to_thread(stt.record_audio)

        if audio_np is not None:
            print(f"ë…¹ìŒëœ ì˜¤ë””ì˜¤ ë°ì´í„° ê¸¸ì´: {len(audio_np)} ìƒ˜í”Œ")
            print("\n--- ë³€í™˜ í…ŒìŠ¤íŠ¸ ---")
            text = await asyncio.to_thread(stt.transcribe_audio, audio_np)
            print(f"\në³€í™˜ëœ í…ìŠ¤íŠ¸ ({stt.provider}): '{text}'")
        else:
            print("ë…¹ìŒì— ì‹¤íŒ¨í•˜ì—¬ ë³€í™˜ í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")

    except RuntimeError as e:
        print(f"STT ì„œë¹„ìŠ¤ ({test_provider}) ì´ˆê¸°í™” ë˜ëŠ” í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
    except Exception as e:
        print(f"í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        traceback.print_exc()

    print("\nSTT ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ ì¢…ë£Œ.")


if __name__ == "__main__":
    try:
        asyncio.run(test_stt_service())
    except KeyboardInterrupt:
        print("\ní…ŒìŠ¤íŠ¸ ì¤‘ë‹¨ë¨.")
    except Exception as e:
        print(f"\ní…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ìµœìƒìœ„ ì˜¤ë¥˜: {e}")
        traceback.print_exc()
